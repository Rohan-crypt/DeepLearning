{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYbOJu82OljDOaYL/oRA/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohan-crypt/DeepLearning/blob/main/DL_lab_Exp_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exp.5: Building Neural Networks from Scratch\n",
        "    · Implement a single neuron with weighted inputs for the AND gate and verify its functionality.\n",
        "   · Extend to a Feedforward Neural Network (FFNN) for XOR/AND operation using multiple layers and neurons.\n",
        "   · Implement a full Multilayer Perceptron (MLP) architecture for solving more complex functions/datasets."
      ],
      "metadata": {
        "id": "0W9pIhtfDpqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_11duCejDmZS",
        "outputId": "1bf1fdaa-d32e-44f9-ed68-848abc2fb125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Part A: AND Gate ===\n",
            "Trained Weights: [0.20405905 0.24612546]\n",
            "Trained Bias: [-0.3836411]\n",
            "Input: [0 0] -> Output: 0\n",
            "Input: [0 1] -> Output: 0\n",
            "Input: [1 0] -> Output: 0\n",
            "Input: [1 1] -> Output: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step activation function\n",
        "def step_function(x):\n",
        "    return 1 if x > 0 else 0\n",
        "\n",
        "# Training data for AND gate\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "Y = np.array([0,0,0,1])\n",
        "\n",
        "# Initialize weights and bias\n",
        "weights = np.random.rand(2)\n",
        "bias = np.random.rand(1)\n",
        "lr = 0.1  # learning rate\n",
        "\n",
        "# Training perceptron\n",
        "for epoch in range(20):\n",
        "    for i in range(len(X)):\n",
        "        z = np.dot(X[i], weights) + bias\n",
        "        y_pred = step_function(z)\n",
        "        error = Y[i] - y_pred\n",
        "        weights += lr * error * X[i]\n",
        "        bias += lr * error\n",
        "\n",
        "print(\"=== Part A: AND Gate ===\")\n",
        "print(\"Trained Weights:\", weights)\n",
        "print(\"Trained Bias:\", bias)\n",
        "\n",
        "# Testing AND gate\n",
        "for i in range(len(X)):\n",
        "    z = np.dot(X[i], weights) + bias\n",
        "    print(f\"Input: {X[i]} -> Output: {step_function(z)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation + derivative\n",
        "def sigmoid(x): return 1/(1+np.exp(-x))\n",
        "def sigmoid_derivative(x): return x*(1-x)\n",
        "\n",
        "# Training data for XOR gate\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "Y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Initialize weights & biases\n",
        "np.random.seed(42)\n",
        "W1 = np.random.randn(2,2)   # 2 inputs -> 2 hidden neurons\n",
        "b1 = np.zeros((1,2))\n",
        "W2 = np.random.randn(2,1)   # 2 hidden -> 1 output\n",
        "b2 = np.zeros((1,1))\n",
        "lr = 0.1\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    hidden = sigmoid(np.dot(X, W1) + b1)\n",
        "    output = sigmoid(np.dot(hidden, W2) + b2)\n",
        "\n",
        "    # Backpropagation\n",
        "    error = Y - output\n",
        "    d_output = error * sigmoid_derivative(output)\n",
        "\n",
        "    error_hidden = d_output.dot(W2.T)\n",
        "    d_hidden = error_hidden * sigmoid_derivative(hidden)\n",
        "\n",
        "    # Update weights\n",
        "    W2 += hidden.T.dot(d_output) * lr\n",
        "    b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "    W1 += X.T.dot(d_hidden) * lr\n",
        "    b1 += np.sum(d_hidden, axis=0, keepdims=True) * lr\n",
        "\n",
        "print(\"\\n=== Part B: XOR Gate ===\")\n",
        "print(\"Final Predictions (rounded):\")\n",
        "print(output.round())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGd_MmnRE_Ds",
        "outputId": "882d345e-5f95-4ed2-deda-95c2d174db6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Part B: XOR Gate ===\n",
            "Final Predictions (rounded):\n",
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target.reshape(-1,1)\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "Y = encoder.fit_transform(y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Sigmoid + derivative\n",
        "def sigmoid(x): return 1/(1+np.exp(-x))\n",
        "def sigmoid_derivative(x): return x*(1-x)\n",
        "\n",
        "# Initialize weights\n",
        "np.random.seed(42)\n",
        "W1 = np.random.randn(4,8)  # 4 inputs -> 8 hidden neurons\n",
        "b1 = np.zeros((1,8))\n",
        "W2 = np.random.randn(8,3)  # 8 hidden -> 3 outputs\n",
        "b2 = np.zeros((1,3))\n",
        "lr = 0.01\n",
        "\n",
        "# Training\n",
        "for epoch in range(1000):\n",
        "    hidden = sigmoid(np.dot(X_train, W1) + b1)\n",
        "    output = sigmoid(np.dot(hidden, W2) + b2)\n",
        "\n",
        "    error = Y_train - output\n",
        "    d_output = error * sigmoid_derivative(output)\n",
        "\n",
        "    error_hidden = d_output.dot(W2.T)\n",
        "    d_hidden = error_hidden * sigmoid_derivative(hidden)\n",
        "\n",
        "    W2 += hidden.T.dot(d_output) * lr\n",
        "    b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "    W1 += X_train.T.dot(d_hidden) * lr\n",
        "    b1 += np.sum(d_hidden, axis=0, keepdims=True) * lr\n",
        "\n",
        "# Training Accuracy\n",
        "preds_train = np.argmax(output, axis=1)\n",
        "true_train = np.argmax(Y_train, axis=1)\n",
        "train_acc = np.mean(preds_train == true_train)\n",
        "\n",
        "# Testing Accuracy\n",
        "hidden_test = sigmoid(np.dot(X_test, W1) + b1)\n",
        "output_test = sigmoid(np.dot(hidden_test, W2) + b2)\n",
        "preds_test = np.argmax(output_test, axis=1)\n",
        "true_test = np.argmax(Y_test, axis=1)\n",
        "test_acc = np.mean(preds_test == true_test)\n",
        "\n",
        "print(\"\\n=== Part C: Iris Dataset (MLP) ===\")\n",
        "print(\"Training Accuracy:\", train_acc)\n",
        "print(\"Testing Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11Jx2GdrFB-W",
        "outputId": "a50b86e9-3cbb-49c3-e103-47cfee162f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Part C: Iris Dataset (MLP) ===\n",
            "Training Accuracy: 0.975\n",
            "Testing Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}